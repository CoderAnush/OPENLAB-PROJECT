"""
STEP 3 & 4: Real-Time Inference & AI Command Protocol
======================================================

This script continuously:
1. Reads live MQ2 & MQ135 from STM32 (UART)
2. Maintains rolling time-window
3. Extracts IDENTICAL features to training
4. Runs model.predict() in real-time
5. Sends deterministic AI commands back to STM32

AI COMMAND PROTOCOL (Simple, STM32-Friendly):
- AI_SAFE      ‚Üí System normal, threshold protection active
- AI_WARN      ‚Üí Trend detected, fan turns ON early
- AI_CRITICAL  ‚Üí Immediate action, max alerting

CRITICAL INVARIANT:
Feature extraction must be BIT-IDENTICAL to training phase.
"""

import serial
import joblib
import numpy as np
import json
import time
from datetime import datetime
from collections import deque

print("="*70)
print("REAL-TIME INFERENCE: Gas/Smoke Detection")
print("="*70)

# ========== LOAD TRAINED MODEL ==========
print("\nüì¶ Loading frozen model...")
try:
    model = joblib.load('ml_models/gas_smoke_rf.pkl')
    feature_names = joblib.load('ml_models/feature_names.pkl')
    with open('ml_models/model_metadata.json', 'r') as f:
        metadata = json.load(f)
    
    print(f"‚úÖ Model loaded: {metadata['model_type']}")
    print(f"‚úÖ Classes: {metadata['classes']}")
    print(f"‚úÖ Features: {feature_names}")
    print(f"‚úÖ Training Accuracy: {metadata['training_accuracy']:.4f}")
    print(f"‚úÖ Test Accuracy: {metadata['test_accuracy']:.4f}")
except Exception as e:
    print(f" ERROR: {e}")
    print(" Run: python ml/train_model.py")
    exit(1)

# ========== CONFIGURATION ==========
SERIAL_PORT = 'COM4'
BAUD_RATE = 9600

WINDOW_SIZE = 60        # Match training (60 samples = ~6.3s at 9.5 Hz)
CONFIDENCE_THRESHOLD = 0.6  # Only act on confident predictions

# Rolling buffers for windowing
mq2_window = deque(maxlen=WINDOW_SIZE)
mq135_window = deque(maxlen=WINDOW_SIZE)

# Logging
INFERENCE_LOG = 'ml_logs/inference_log.csv'
import os
os.makedirs('ml_logs', exist_ok=True)

log_file = open(INFERENCE_LOG, 'w')
log_file.write('timestamp,mq2,mq135,prediction,confidence_safe,confidence_warn,confidence_critical,ai_command\n')
log_file.flush()

# State tracking
last_prediction = 'SAFE'
consecutive_warns = 0
CONFIRMATION_THRESHOLD = 2  # Confirm WARN with 2 consecutive predictions

print(f"\n‚öôÔ∏è  Configuration:")
print(f"   Window Size: {WINDOW_SIZE} samples (~6.3 sec)")
print(f"   Confidence Threshold: {CONFIDENCE_THRESHOLD:.2f}")
print(f"   Serial Port: {SERIAL_PORT} @ {BAUD_RATE} baud")
print(f"   Log File: {INFERENCE_LOG}")

# ========== FEATURE EXTRACTION (IDENTICAL TO TRAINING) ==========
def extract_features(mq2_buffer, mq135_buffer):
    """
    Extract EXACT SAME features as training.
    If this changes, model predictions are invalid.
    """
    if len(mq2_buffer) < WINDOW_SIZE or len(mq135_buffer) < WINDOW_SIZE:
        return None  # Not enough data yet
    
    mq2_arr = np.array(list(mq2_buffer))
    mq135_arr = np.array(list(mq135_buffer))
    
    features = {
        'mq2_now': float(mq2_arr[-1]),
        'mq135_now': float(mq135_arr[-1]),
        'mq2_delta': float(mq2_arr[-1] - mq2_arr[0]),
        'mq135_delta': float(mq135_arr[-1] - mq135_arr[0]),
        'mq2_mean_window': float(np.mean(mq2_arr)),
        'mq135_mean_window': float(np.mean(mq135_arr)),
        'mq2_max_window': float(np.max(mq2_arr)),
        'mq135_max_window': float(np.max(mq135_arr))
    }
    
    return features

# ========== PREDICTION & COMMAND GENERATION ==========
def predict_and_command(features):
    """
    Run model.predict() and convert to AI command.
    
    Returns: (prediction, confidence, ai_command)
    """
    # Ensure feature order matches training
    feature_vector = np.array([[features[fname] for fname in feature_names]])
    
    # Get prediction and confidence
    prediction = model.predict(feature_vector)[0]
    confidences = model.predict_proba(feature_vector)[0]
    class_idx = list(model.classes_).index(prediction)
    confidence = confidences[class_idx]
    
    # Convert to AI commands
    if confidence < CONFIDENCE_THRESHOLD:
        ai_command = 'AI_SAFE'  # Low confidence = safe assumption
    elif prediction == 'CRITICAL':
        ai_command = 'AI_CRITICAL'
    elif prediction == 'WARN':
        ai_command = 'AI_WARN'
    else:
        ai_command = 'AI_SAFE'
    
    return prediction, confidence, ai_command

# ========== SERIAL COMMUNICATION ==========
def send_command_to_stm32(ser, command):
    """Send AI command to STM32"""
    try:
        ser.write(f"{command}\n".encode())
        print(f"   ‚Üí STM32: {command}")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Serial write failed: {e}")

# ========== MAIN INFERENCE LOOP ==========
def main():
    """Real-time inference loop"""
    global consecutive_warns, last_prediction
    
    print("\n" + "="*70)
    print("üî¥ STARTING REAL-TIME INFERENCE...")
    print("="*70)
    print("Connecting to STM32...\n")
    
    try:
        ser = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=1)
        time.sleep(2)  # Allow port to stabilize
        print(f"‚úÖ Connected to {SERIAL_PORT}\n")
        
    except Exception as e:
        print(f" ERROR: Cannot open {SERIAL_PORT}: {e}")
        return
    
    sample_count = 0
    
    try:
        while True:
            try:
                # Read line from STM32
                line = ser.readline().decode('utf-8', errors='ignore').strip()
                
                if not line or 'MQ2' not in line:
                    continue
                
                # Parse "MQ2: 1.23, MQ135: 0.56"
                try:
                    parts = line.split(',')
                    mq2_str = parts[0].split(':')[1].strip().replace('V', '')
                    mq135_str = parts[1].split(':')[1].strip().replace('V', '')
                    
                    mq2_val = float(mq2_str)
                    mq135_val = float(mq135_str)
                except:
                    continue
                
                # Add to rolling windows
                mq2_window.append(mq2_val)
                mq135_window.append(mq135_val)
                sample_count += 1
                
                # Try to extract features
                features = extract_features(mq2_window, mq135_window)
                
                if features is None:
                    # Still collecting data
                    if sample_count % 10 == 0:
                        progress = len(mq2_window)
                        print(f"   Buffering: {progress}/{WINDOW_SIZE} samples...", end='\r')
                    continue
                
                # Clear progress line
                print("                                      ", end='\r')
                
                # Run inference
                prediction, confidence, ai_command = predict_and_command(features)
                
                # Multi-sample confirmation for WARN (reduce false positives)
                if prediction == 'WARN':
                    consecutive_warns += 1
                    if consecutive_warns < CONFIRMATION_THRESHOLD:
                        ai_command = 'AI_SAFE'  # Wait for confirmation
                else:
                    consecutive_warns = 0
                
                # Log prediction
                timestamp = datetime.now().isoformat()
                log_file.write(
                    f"{timestamp},{mq2_val:.3f},{mq135_val:.3f},"
                    f"{prediction},{confidences[0]:.4f},"
                    f"{confidences[1]:.4f},{confidences[2]:.4f},"
                    f"{ai_command}\n"
                )
                log_file.flush()
                
                # Display and send command
                if prediction != last_prediction or sample_count % 50 == 0:
                    print(f"\n[{timestamp}]")
                    print(f"   MQ2: {mq2_val:.2f}V | MQ135: {mq135_val:.2f}V")
                    print(f"   Prediction: {prediction} ({confidence:.2%} confidence)")
                    print(f"   ‚ûú Command: {ai_command}")
                    
                    # Send to STM32
                    send_command_to_stm32(ser, ai_command)
                    last_prediction = prediction
                
            except KeyboardInterrupt:
                raise
            except Exception as e:
                continue
    
    except KeyboardInterrupt:
        print("\n\nüõë Inference stopped by user")
    finally:
        ser.close()
        log_file.close()
        print(f"\n‚úÖ Logged to: {INFERENCE_LOG}")
        print(f"   Total samples processed: {sample_count}")

# ========== FAIL-SAFE & ARCHITECTURE NOTES ==========
ARCHITECTURE_NOTES = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë DEPLOYMENT ARCHITECTURE & FAIL-SAFE LOGIC                                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

WHERE IS THE MODEL DEPLOYED?
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚úì Model is on PC (this Python script)
‚úó NOT on STM32 (microcontroller)
‚úó NOT in cloud
‚úó NOT in mobile app

Real-time flow:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         UART          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STM32   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ(MQ2, MQ135)‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ PC (this script)   ‚îÇ
‚îÇ  Board   ‚îÇ                        ‚îÇ (trained model)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ‚îÄ‚îÄ(AI_WARN)‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚ñ≤ Actions:                           ‚ñ≤ Inference:
   ‚îú‚îÄ Fan ON/OFF                        ‚îú‚îÄ Extract features
   ‚îú‚îÄ Buzzer                            ‚îú‚îÄ predict()
   ‚îú‚îÄ LEDs                              ‚îú‚îÄ Generate command
   ‚îî‚îÄ Relay                             ‚îî‚îÄ Send back to STM32

FAIL-SAFE HIERARCHY
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1Ô∏è‚É£ AI_CRITICAL received    ‚Üí Fan ON immediately (highest priority)
2Ô∏è‚É£ Threshold crossed       ‚Üí Fan ON immediately (built-in protection)
3Ô∏è‚É£ Bluetooth lost          ‚Üí Thresholds continue to protect
4Ô∏è‚É£ AI node crashed         ‚Üí STM32 continues with thresholds only

KEY INVARIANTS (MUST NEVER VIOLATE)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚úì Feature extraction is IDENTICAL between training & deployment
‚úì Threshold logic is ALWAYS active (AI is complementary)
‚úì AI commands are SIMPLE (AI_SAFE/WARN/CRITICAL, not floats)
‚úì Model weights are FROZEN (no retraining in production)
‚úì Predictions are LOGGED (for analysis & viva defense)

WHY THIS ARCHITECTURE?
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ PC has CPU power for ML inference
‚Ä¢ STM32 has real-time guarantees for control
‚Ä¢ Separation of concerns: sensing + ML + actuation
‚Ä¢ STM32 never depends on ML (always safe)
‚Ä¢ Can update ML without touching embedded code

EARLY PREDICTION CONCEPT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Traditional: Fan ON when MQ2 > 2.0V ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
AI-Assisted: Fan ON when trend ‚Üí WARN ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚îÄ‚îÄ  (earlier)

This gives operator 10-30 seconds to react before critical.
"""

if __name__ == '__main__':
    print(ARCHITECTURE_NOTES)
    main()
